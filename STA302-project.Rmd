---
title: "EPL STA302 GOOD"
author: "Domenico Oppedisano"
date: "2024-08-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#installing packages that may be used
# install.packages("MASS")
# install.packages("gapminder")
# install.packages("leaps")
# install.packages("usdm")
# install.packages("car")
# install.packages("corrplot")
# install.packages("texreg")
# install.packages("MPV")
# install.packages("faraway")
# install.packages("lmtest")
# install.packages("nortest")
# install.packages("scipy.stats")
# install.packages("sandwich")
# install.packages("car")
```

```{r}
#making sure the packages are ready to use
library(dplyr)
library(gapminder)
library(leaps)
library(glmnet)
library(ggplot2)
library(MASS)
#library(usdm)
#library(car)
library(corrplot)
library(texreg)
library(MPV)
#library(faraway)
library(lmtest)
library(nortest)
library(car)
```

```{r}
#Assigning the dataset to variable epl
epl <- read.csv("epl_data.csv")

#Selecting variables of interest and creating a matrix with just those values
eplFiltered <- epl %>% select_(6, 7, 8, 10, 20, 24, 27, 28, 29, 40, 41, 43, 44, 56, 57, 58, 59)
head(eplFiltered)

#Removing all NA values, leaves us with 501 observations
eplWoNa <- na.omit(eplFiltered)
nrow(eplWoNa)

s <- sum(eplWoNa$Appearances == 0)

eplPos <- eplWoNa[!(eplWoNa$Appearances %in% 0),]
nrow(eplPos)
```

```{r}
#Conducting variable selection using AIC

#Fitting a model using all variables
modAll <- lm(Appearances ~ Age + Wins + Goals + Hit.woodwork + Tackles + 
              Blocked.shots + Interceptions + Clearances + Assists + Passes + Big.chances.created +
              Crosses + Yellow.cards + Red.cards + Fouls + Offsides, data = eplPos)
#Taking a look at the model
summary(modAll)

#Checking the value of AIC for the model with all variables
AIC(modAll)

#Creating an intercept only model
mod0 <- lm(Appearances ~ 1, data = eplPos)
AIC(mod0)
summary(mod0)$r.squared
```

```{r}
#Conducting backward elimination on the full model (modAll)
bmod <- stepAIC(object = modAll, direction = "backward", trace = FALSE)
coef(bmod)

#Checking the adjusted R-squared after the variable selection (backward)
summary(bmod)$adj.r.squared

#Conducting forward elimination on the empty model, full model as scope
fmod <- stepAIC(object = mod0, direction = "forward", scope = formula(modAll), trace = FALSE)
coef(fmod)

#Checking the adjusted R-squared after the variable selection (forward)
summary(fmod)$adj.r.squared

#Both methods select the same variables :)


#This shows that the AIC decreases with each added variable
bmod$anova
fmod$anova
```

```{r}
#Partial F-test

#The best model given by both forwards and backwards methods
optimodel <- lm(Appearances ~ Wins + Fouls + Interceptions + Blocked.shots + 
                  Offsides + Crosses + Clearances + Goals + Hit.woodwork + 
                  Age + Tackles, data = eplPos)
#Second best forward method model
fSecondBest <- lm(Appearances ~ Wins + Fouls + Interceptions + Blocked.shots + 
                    Offsides + Crosses + Clearances + Goals + Hit.woodwork + 
                    Tackles, data = eplPos)

fThirdBest <- lm(Appearances ~ Wins + Fouls + Interceptions + Blocked.shots + 
                    Offsides + Crosses + Clearances + Goals + Hit.woodwork, data = eplPos)

fFourthBest <- lm(Appearances ~ Wins + Fouls + Interceptions + Blocked.shots + 
                    Offsides + Crosses + Clearances + Goals, data = eplPos)
#Second best backward method model
bSecondBest <- lm(Appearances ~ Age + Wins + Goals + Hit.woodwork + Tackles + Blocked.shots + 
                    Interceptions + Clearances + Crosses + Yellow.cards + Fouls + 
                    Offsides, data = eplPos)

#The output gives Pr(>F) = 0.1109, we cannot reject null hypothesis do not keep variable
anova(optimodel, fSecondBest)

#Cannot reject null hypothesis at 0.05, p-value = 0.0824
anova(fSecondBest, fThirdBest)

#fThirdBest gives us the best model, the below test give p-value 0.00523
#We reject null hypothesis that new variable is 0
anova(fThirdBest, fFourthBest)

#The output gives Pr(>F) = 0.2957, we cannot reject null hypothesis, decide to remove excess variable
anova(optimodel, bSecondBest)

#The partial F tests above, along with our stepAIC variable selection tell us
#fThirdBest gives us the best model
#Between fThirdBest and optimodel, AIC changes by less than 2, not significant
#Our partial F tests tell us to remove the two variables differing between optimodel and fThirdBest
#We also like the simplicity of having less covariates :)

optimal <- lm(Appearances ~ Wins + Fouls + Interceptions + Blocked.shots + 
                    Offsides + Crosses + Clearances + Goals + Hit.woodwork, data = eplPos)
```


```{r}
#Assumption Checking


# Checking residuals for normality
par(mfrow = c(2, 2))

# Histogram of residuals
hist(residuals(optimal), main = "Histogram of Residuals", xlab = "Residuals", breaks = 20)

# Q-Q plot of residuals
qqnorm(residuals(optimal))
qqline(residuals(optimal), col = "red")

# Residuals vs Fitted plot
plot(fitted(optimal), residuals(optimal),
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

# Scale-Location plot
plot(optimal, which = 3)

# Statistical tests for normality
shapiro.test(residuals(optimal))

# Checking for homoscedasticity using Breusch-Pagan test
library(lmtest)
bptest(optimal)

```

```{r}
# Extract the covariates (excluding the intercept)
covariates <- attr(terms(optimal), "term.labels")

# Subset the original dataset to include only these covariates
epl_subset <- eplPos[, covariates]

# Create a pairwise plot using base R
pairs(epl_subset, main = "Pairwise Plot of Covariates in the Optimal Model")

```

```{r}
#Using the pairwise plots, choosing and applying transformations to Appearances and Clearances

optimal_sqrt <- lm(sqrt(Appearances) ~ Wins + Fouls + Interceptions + Blocked.shots + 
                   Offsides + Crosses + log(Clearances +1) + Goals + Hit.woodwork, data = eplPos)

```

```{r}
# Checking residuals for normality
par(mfrow = c(2, 2))

# Histogram of residuals
hist(residuals(optimal_sqrt), main = "Histogram of Residuals", xlab = "Residuals", breaks = 20)

# Q-Q plot of residuals
qqnorm(residuals(optimal_sqrt))
qqline(residuals(optimal_sqrt), col = "red")

# Residuals vs Fitted plot
plot(fitted(optimal_sqrt), residuals(optimal_sqrt),
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

# Scale-Location plot
plot(optimal, which = 3)

# Statistical tests for normality
shapiro.test(residuals(optimal_sqrt))
```

```{r}
# Calculate Cook's Distance
cooks_d <- cooks.distance(optimal)

# Identify influential points where Cook's distance is greater than a threshold (commonly 4/n)
influential_points <- which(cooks_d > 4/nrow(eplPos))

# Plot Cooks Distance
plot(cooks_d, type = "h", main = "Cook's Distance", ylab = "Cook's Distance", xlab = "Observation Index")
abline(h = 4/nrow(eplPos), col = "red", lty = 2)
points(influential_points, cooks_d[influential_points], col = "blue", pch = 19)




# Calculate DFBETAS
dfbetas_values <- dfbetas(optimal)
threshold <- 2/sqrt(nrow(eplPos))

# Identify influential points using DFBETAS
influential_points_dfbetas <- which(apply(abs(dfbetas_values), 1, max) > threshold)

# Plot DFBETAS
par(mfrow = c(2, 5))  # Adjusting the layout for multiple plots
for (i in 1:ncol(dfbetas_values)) {
  plot(dfbetas_values[, i], type = "h", main = colnames(dfbetas_values)[i],
       ylab = "DFBETAS", xlab = "Observation Index")
  abline(h = threshold, col = "red", lty = 2)
  abline(h = -threshold, col = "red", lty = 2)
  points(influential_points_dfbetas, dfbetas_values[influential_points_dfbetas, i], col = "blue", pch = 19)
}

```


```{r}
eplPos_cleaned <- eplPos[-influential_points, ]

optimal_cleaned <- lm(Appearances ~ Wins + Fouls + Interceptions + Blocked.shots + 
                      Offsides + Crosses + Clearances + Goals + Hit.woodwork, data = eplPos_cleaned)
```

```{r}
# Checking residuals for normality
par(mfrow = c(2, 2))

# Histogram of residuals
hist(residuals(optimal_cleaned), main = "Histogram of Residuals", xlab = "Residuals", breaks = 20)

# Q-Q plot of residuals
qqnorm(residuals(optimal_cleaned))
qqline(residuals(optimal_cleaned), col = "red")

# Residuals vs Fitted plot
plot(fitted(optimal_cleaned), residuals(optimal_cleaned),
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")

# Scale-Location plot
plot(optimal, which = 3)

# Statistical tests for normality
shapiro.test(residuals(optimal_cleaned))
```

VIF of the cleaned optimal model
```{r}
#vif_factors <-vif(modAll)
#vif_factors <-vif(mod0)
#vif_factors <-vif(optimodel)
#vif_factors <-vif(fSecondBest)
#vif_factors <-vif(fThirdBest)
#vif_factors <-vif(fFourthBest)
#vif_factors <-vif(bSecondBest)
#vif_factors <-vif(optimal)
#vif_factors <-vif(optimal_sqrt)
vif_factors <-vif(optimal_cleaned)
vif_factors
# Visualizing VIF
barplot(vif_factors, col = "red", main = "Variance Inflation Factor", las=2,cex.names=0.8)
```
